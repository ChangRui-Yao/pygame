#-使用scrapy共有四个步骤
        #----1创建一个scrapy项目
        #----2定义一个Item容器
        #----3编写爬虫
        #----4存储内容


#-------利用scrapy atartproject wenjianjia1
                #-----创建一个scrapy项目

#-------在itmes.py里定义了三个


#-----编写爬虫是在spiders的文件夹里面  其内部是用户编写用于从网站上爬取数据的类
        #-其包含了一个下载的初始URL  然后是如何跟进网页中的链接以及如何分析网页中的内容
        #_还由提取生成item的方法

        #-----如何爬取网页代码的方法已经写好   如何在其中获得你想要的东西呢

            #----过去我们是使用正则表达式
            #在scrapy中使用一种基于Xpath  和CSS的表达式机制:Scrary Selectors
                #-scrapy是一个选择器，他有四个基本的方法  这四种方法就相当于筛子 从一堆源代码里获得你需要的东西
                    #1------xpath():传入xpath表达式，返回该表达式所对应的所有节点的selector list列表
                    #2------css():传入css表达式，返回该表达式所对应的节点的selector list()列表
                    #3------extract():序列化该节点为unicode字符串并返回list
                    #4------re():根据传入的正则表达式对数据进行提取，返回unicode字符串list列表






#---什么是xpath?
        #--Xpath是一门在网页中中查找特定信息的语言  所以用xpath来筛选数据，要比正则表达式容易一些
